{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from praw) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.12.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\aditya\n",
      "[nltk_data]     kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install praw\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Reddit AuthO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='WK7Bb4kSnRez8g',\n",
    "                     client_secret='NYWBOS04ouTSPO0cKhsMLqs-SWQ',\n",
    "                     user_agent='Reddit_India_Data')\n",
    "india_subreddit = reddit.subreddit('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "post_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def readableTime(created):\n",
    "    return dt.datetime.utcfromtimestamp(created)\n",
    "\n",
    "\n",
    "#To convert data elements into string objects\n",
    "def toStr(item):\n",
    "    return str(item)\n",
    "\n",
    "_replace = re.compile('[/(){}\\|@,;]')\n",
    "badSymbols = re.compile('[^0-9a-z #+_]')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#To clean text within dataset\n",
    "\n",
    "# sentences = \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def cleanText(string):\n",
    "    string = BeautifulSoup(string, \"lxml\").string\n",
    "    string = string.lower() \n",
    "    string = _replace.sub(' ', string)\n",
    "    string = badSymbols.sub('', string)\n",
    "    string=nltk.sent_tokenize(string)\n",
    "    words = [lemmatizer.lemmatize(word) for word in string if word not in set(stopwords.words('english'))]\n",
    "    string= ' '.join(words)  \n",
    "#     string = ' '.join(word for word in string.split() if word not in stopWords)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    submissions = india_subreddit.search(f\"flair_name:{flair}\",limit=500)\n",
    "    for submission in submissions:\n",
    "        post_dict.append([submission.title,\n",
    "                submission.id,\n",
    "                submission.link_flair_text,\n",
    "                submission.author,\n",
    "                submission.url,\n",
    "                submission.num_comments,\n",
    "                submission.score,\n",
    "                submission.created])\n",
    "post_dict = pd.DataFrame(post_dict,columns=['title', 'id', 'flair', 'author', 'url', 'num_comments', 'score', 'created'])\n",
    "topics = pd.DataFrame(post_dict)\n",
    "#Sorting data based in ascending order of flair\n",
    "topics.sort_values('flair', inplace=True)\n",
    "#Changing Unix time to UTC time.\n",
    "topics['created'] = topics['created'].apply(readableTime)\n",
    "# del topics['created']\n",
    "#Deleting any duplicate rows\n",
    "topics.drop_duplicates(subset=None, inplace=True)\n",
    "topics.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Cleaning and Text Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv')\n",
    "df.head()\n",
    "df['title'] =df['title'].apply(toStr)\n",
    "df['title'] =df['title'].apply(cleanText)\n",
    "df['num_comments'] =df['num_comments'].apply(toStr)\n",
    "df['num_comments'] =df['num_comments'].apply(cleanText)\n",
    "df['author'] =df['author'].apply(toStr)\n",
    "df['author'] =df['author'].apply(cleanText)\n",
    "# feature_Grp = df['title'] + df['url']\n",
    "# df['feature_Grp'] = feature_Grp\n",
    "df.to_csv('Final_formatted_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Final_formatted_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi  im anish majumdar  author of the isolation...</td>\n",
       "      <td>2059oa</td>\n",
       "      <td>AMA</td>\n",
       "      <td>anish_majumdar</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/2059oa...</td>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>2014-03-11 15:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>np i am a dentist ama</td>\n",
       "      <td>4giohy</td>\n",
       "      <td>AMA</td>\n",
       "      <td>periomate</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4giohy...</td>\n",
       "      <td>297</td>\n",
       "      <td>95</td>\n",
       "      <td>2016-04-26 12:58:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi reddit  im siddharth agarwal  im currently ...</td>\n",
       "      <td>4saxeh</td>\n",
       "      <td>AMA</td>\n",
       "      <td>iamasid</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4saxeh...</td>\n",
       "      <td>147</td>\n",
       "      <td>340</td>\n",
       "      <td>2016-07-11 13:32:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ama hi r india im a ca and would love to answe...</td>\n",
       "      <td>5tcgn5</td>\n",
       "      <td>AMA</td>\n",
       "      <td>cap_nemo_1984</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/5tcgn5...</td>\n",
       "      <td>206</td>\n",
       "      <td>77</td>\n",
       "      <td>2017-02-11 05:43:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey reddit i am sandeep goenka  cofounder of z...</td>\n",
       "      <td>5e3mni</td>\n",
       "      <td>AMA</td>\n",
       "      <td>goenkasandeep</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/5e3mni...</td>\n",
       "      <td>218</td>\n",
       "      <td>100</td>\n",
       "      <td>2016-11-21 11:44:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      id flair  \\\n",
       "0  hi  im anish majumdar  author of the isolation...  2059oa   AMA   \n",
       "1                              np i am a dentist ama  4giohy   AMA   \n",
       "2  hi reddit  im siddharth agarwal  im currently ...  4saxeh   AMA   \n",
       "3  ama hi r india im a ca and would love to answe...  5tcgn5   AMA   \n",
       "4  hey reddit i am sandeep goenka  cofounder of z...  5e3mni   AMA   \n",
       "\n",
       "           author                                                url  \\\n",
       "0  anish_majumdar  https://www.reddit.com/r/india/comments/2059oa...   \n",
       "1       periomate  https://www.reddit.com/r/india/comments/4giohy...   \n",
       "2         iamasid  https://www.reddit.com/r/india/comments/4saxeh...   \n",
       "3   cap_nemo_1984  https://www.reddit.com/r/india/comments/5tcgn5...   \n",
       "4   goenkasandeep  https://www.reddit.com/r/india/comments/5e3mni...   \n",
       "\n",
       "   num_comments  score              created  \n",
       "0            36     67  2014-03-11 15:53:58  \n",
       "1           297     95  2016-04-26 12:58:58  \n",
       "2           147    340  2016-07-11 13:32:51  \n",
       "3           206     77  2017-02-11 05:43:55  \n",
       "4           218    100  2016-11-21 11:44:31  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
