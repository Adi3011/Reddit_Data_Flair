{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.5.0-py3-none-any.whl (176 kB)\n",
      "Collecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from praw) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n",
      "Installing collected packages: update-checker, prawcore, praw\n",
      "Successfully installed praw-7.5.0 prawcore-2.3.0 update-checker-0.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\aditya\n",
      "[nltk_data]     kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "!pip install praw\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Reddit AuthO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='WK7Bb4kSnRez8g',\n",
    "                     client_secret='NYWBOS04ouTSPO0cKhsMLqs-SWQ',\n",
    "                     user_agent='Reddit_India_Data')\n",
    "india_subreddit = reddit.subreddit('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "post_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def readableTime(created):\n",
    "    return dt.datetime.utcfromtimestamp(created)\n",
    "\n",
    "\n",
    "#To convert data elements into string objects\n",
    "def toStr(item):\n",
    "    return str(item)\n",
    "\n",
    "_replace = re.compile('[/(){}\\|@,;]')\n",
    "badSymbols = re.compile('[^0-9a-z #+_]')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#To clean text within dataset\n",
    "\n",
    "# sentences = \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def cleanText(string):\n",
    "    string = BeautifulSoup(string, \"lxml\").string\n",
    "    string = string.lower() \n",
    "    string = _replace.sub(' ', string)\n",
    "    string = badSymbols.sub('', string)\n",
    "    string=nltk.sent_tokenize(string)\n",
    "    words = [lemmatizer.lemmatize(word) for word in string if word not in set(stopwords.words('english'))]\n",
    "    string= ' '.join(words)  \n",
    "#     string = ' '.join(word for word in string.split() if word not in stopWords)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    submissions = india_subreddit.search(f\"flair_name:{flair}\",limit=100)\n",
    "    for submission in submissions:\n",
    "        post_dict.append([submission.title,\n",
    "                submission.id,\n",
    "                submission.link_flair_text,\n",
    "                submission.author,\n",
    "                submission.url,\n",
    "                submission.num_comments,\n",
    "                submission.score,\n",
    "                submission.created])\n",
    "post_dict = pd.DataFrame(post_dict,columns=['title', 'id', 'flair', 'author', 'url', 'num_comments', 'score', 'created'])\n",
    "topics = pd.DataFrame(post_dict)\n",
    "#Sorting data based in ascending order of flair\n",
    "topics.sort_values('flair', inplace=True)\n",
    "#Changing Unix time to UTC time.\n",
    "topics['timestamp'] = topics['created'].apply(readableTime)\n",
    "del topics['created']\n",
    "#Deleting any duplicate rows\n",
    "topics.drop_duplicates(subset=None, inplace=True)\n",
    "topics.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Cleaning and Text Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv')\n",
    "df.head()\n",
    "df['title'] =df['title'].apply(toStr)\n",
    "df['title'] =df['title'].apply(cleanText)\n",
    "feature_Grp = df['title'] + df['url']\n",
    "df = df.assign(feature_Grp = feature_Grp)\n",
    "df.to_csv('Final_formatted_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Final_formatted_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>feature_Grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am a lesser known indian author my 2nd book ...</td>\n",
       "      <td>5unqxo</td>\n",
       "      <td>AMA</td>\n",
       "      <td>legalindia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/5unqxo...</td>\n",
       "      <td>145</td>\n",
       "      <td>93</td>\n",
       "      <td>2017-02-17 18:27:13</td>\n",
       "      <td>i am a lesser known indian author my 2nd book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am sanjeev sabhlok  joined ias in 1982 and r...</td>\n",
       "      <td>9mxy2y</td>\n",
       "      <td>AMA</td>\n",
       "      <td>sabhlok</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/9mxy2y...</td>\n",
       "      <td>304</td>\n",
       "      <td>187</td>\n",
       "      <td>2018-10-10 09:30:47</td>\n",
       "      <td>i am sanjeev sabhlok  joined ias in 1982 and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey  reddit india we are the founding editors ...</td>\n",
       "      <td>8idukp</td>\n",
       "      <td>AMA</td>\n",
       "      <td>thewire_in</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/8idukp...</td>\n",
       "      <td>293</td>\n",
       "      <td>418</td>\n",
       "      <td>2018-05-10 10:26:40</td>\n",
       "      <td>hey  reddit india we are the founding editors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi im shashi tharoor ask me anything on india ...</td>\n",
       "      <td>626l9b</td>\n",
       "      <td>AMA</td>\n",
       "      <td>shashitharoor2017</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/626l9b...</td>\n",
       "      <td>496</td>\n",
       "      <td>1602</td>\n",
       "      <td>2017-03-29 13:25:30</td>\n",
       "      <td>hi im shashi tharoor ask me anything on india ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ama on aadhaar with kiran jonnalagadda  anivar...</td>\n",
       "      <td>7sw2bj</td>\n",
       "      <td>AMA</td>\n",
       "      <td>kumbhakaran</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/7sw2bj...</td>\n",
       "      <td>458</td>\n",
       "      <td>313</td>\n",
       "      <td>2018-01-25 13:31:13</td>\n",
       "      <td>ama on aadhaar with kiran jonnalagadda  anivar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      id flair  \\\n",
       "0  i am a lesser known indian author my 2nd book ...  5unqxo   AMA   \n",
       "1  i am sanjeev sabhlok  joined ias in 1982 and r...  9mxy2y   AMA   \n",
       "2  hey  reddit india we are the founding editors ...  8idukp   AMA   \n",
       "3  hi im shashi tharoor ask me anything on india ...  626l9b   AMA   \n",
       "4  ama on aadhaar with kiran jonnalagadda  anivar...  7sw2bj   AMA   \n",
       "\n",
       "              author                                                url  \\\n",
       "0         legalindia  https://www.reddit.com/r/india/comments/5unqxo...   \n",
       "1            sabhlok  https://www.reddit.com/r/india/comments/9mxy2y...   \n",
       "2         thewire_in  https://www.reddit.com/r/india/comments/8idukp...   \n",
       "3  shashitharoor2017  https://www.reddit.com/r/india/comments/626l9b...   \n",
       "4        kumbhakaran  https://www.reddit.com/r/india/comments/7sw2bj...   \n",
       "\n",
       "   num_comments  score            timestamp  \\\n",
       "0           145     93  2017-02-17 18:27:13   \n",
       "1           304    187  2018-10-10 09:30:47   \n",
       "2           293    418  2018-05-10 10:26:40   \n",
       "3           496   1602  2017-03-29 13:25:30   \n",
       "4           458    313  2018-01-25 13:31:13   \n",
       "\n",
       "                                         feature_Grp  \n",
       "0  i am a lesser known indian author my 2nd book ...  \n",
       "1  i am sanjeev sabhlok  joined ias in 1982 and r...  \n",
       "2  hey  reddit india we are the founding editors ...  \n",
       "3  hi im shashi tharoor ask me anything on india ...  \n",
       "4  ama on aadhaar with kiran jonnalagadda  anivar...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
