{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "reddit_data = pd.read_csv('Final_formatted_data.csv')\n",
    "reddit_data.head()\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>feature_Grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am a lesser known indian author my 2nd book ...</td>\n",
       "      <td>5unqxo</td>\n",
       "      <td>AMA</td>\n",
       "      <td>legalindia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/5unqxo...</td>\n",
       "      <td>145</td>\n",
       "      <td>93</td>\n",
       "      <td>2017-02-17 18:27:13</td>\n",
       "      <td>i am a lesser known indian author my 2nd book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am sanjeev sabhlok  joined ias in 1982 and r...</td>\n",
       "      <td>9mxy2y</td>\n",
       "      <td>AMA</td>\n",
       "      <td>sabhlok</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/9mxy2y...</td>\n",
       "      <td>304</td>\n",
       "      <td>187</td>\n",
       "      <td>2018-10-10 09:30:47</td>\n",
       "      <td>i am sanjeev sabhlok  joined ias in 1982 and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey  reddit india we are the founding editors ...</td>\n",
       "      <td>8idukp</td>\n",
       "      <td>AMA</td>\n",
       "      <td>thewire_in</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/8idukp...</td>\n",
       "      <td>293</td>\n",
       "      <td>418</td>\n",
       "      <td>2018-05-10 10:26:40</td>\n",
       "      <td>hey  reddit india we are the founding editors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi im shashi tharoor ask me anything on india ...</td>\n",
       "      <td>626l9b</td>\n",
       "      <td>AMA</td>\n",
       "      <td>shashitharoor2017</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/626l9b...</td>\n",
       "      <td>496</td>\n",
       "      <td>1602</td>\n",
       "      <td>2017-03-29 13:25:30</td>\n",
       "      <td>hi im shashi tharoor ask me anything on india ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ama on aadhaar with kiran jonnalagadda  anivar...</td>\n",
       "      <td>7sw2bj</td>\n",
       "      <td>AMA</td>\n",
       "      <td>kumbhakaran</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/7sw2bj...</td>\n",
       "      <td>458</td>\n",
       "      <td>313</td>\n",
       "      <td>2018-01-25 13:31:13</td>\n",
       "      <td>ama on aadhaar with kiran jonnalagadda  anivar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      id flair  \\\n",
       "0  i am a lesser known indian author my 2nd book ...  5unqxo   AMA   \n",
       "1  i am sanjeev sabhlok  joined ias in 1982 and r...  9mxy2y   AMA   \n",
       "2  hey  reddit india we are the founding editors ...  8idukp   AMA   \n",
       "3  hi im shashi tharoor ask me anything on india ...  626l9b   AMA   \n",
       "4  ama on aadhaar with kiran jonnalagadda  anivar...  7sw2bj   AMA   \n",
       "\n",
       "              author                                                url  \\\n",
       "0         legalindia  https://www.reddit.com/r/india/comments/5unqxo...   \n",
       "1            sabhlok  https://www.reddit.com/r/india/comments/9mxy2y...   \n",
       "2         thewire_in  https://www.reddit.com/r/india/comments/8idukp...   \n",
       "3  shashitharoor2017  https://www.reddit.com/r/india/comments/626l9b...   \n",
       "4        kumbhakaran  https://www.reddit.com/r/india/comments/7sw2bj...   \n",
       "\n",
       "   num_comments  score            timestamp  \\\n",
       "0           145     93  2017-02-17 18:27:13   \n",
       "1           304    187  2018-10-10 09:30:47   \n",
       "2           293    418  2018-05-10 10:26:40   \n",
       "3           496   1602  2017-03-29 13:25:30   \n",
       "4           458    313  2018-01-25 13:31:13   \n",
       "\n",
       "                                         feature_Grp  \n",
       "0  i am a lesser known indian author my 2nd book ...  \n",
       "1  i am sanjeev sabhlok  joined ias in 1982 and r...  \n",
       "2  hey  reddit india we are the founding editors ...  \n",
       "3  hi im shashi tharoor ask me anything on india ...  \n",
       "4  ama on aadhaar with kiran jonnalagadda  anivar...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing varied Scikit-learn ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayse Classifier\n",
    "def naiveBayse(X_train, X_test, y_train, y_test):\n",
    "    nb = Pipeline([('vect', CountVectorizer(max_features = 1000)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    print(f\"NB Accuracy: {accuracy_score(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "def logReg(X_train, X_test, y_train, y_test):\n",
    "    logreg = Pipeline([('vect', CountVectorizer(max_features = 1000)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy_score(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Support Vector Machine \n",
    "def svmLinear(X_train, X_test, y_train, y_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer(max_features = 1000)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None)),\n",
    "               ])\n",
    "    sgd.fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_test)\n",
    "    print(f\"Linear SVM Accuracy: {accuracy_score(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    rf = Pipeline([('vect', CountVectorizer(max_features=1000)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf', RandomForestClassifier(n_estimators = 500, random_state = 42)),\n",
    "                  ])\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(f\"Random Forest accuracy: {accuracy_score(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Testing and Printing Accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reddit_data['flair'] #Independent variable\n",
    "def train_test(X):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state = 42)\n",
    "    naiveBayse(X_train, X_test, y_train, y_test)\n",
    "    logReg(X_train, X_test, y_train, y_test)\n",
    "    svmLinear(X_train, X_test, y_train, y_test)\n",
    "    randomForest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing value of Dependent variable and calling train_test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair detection accuracy using TITLE as feature\n",
      "\n",
      "NB Accuracy: 0.4638888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.46111111111111114\n",
      "Linear SVM Accuracy: 0.48055555555555557\n",
      "Random Forest accuracy: 0.43333333333333335\n",
      "Flair detection accuracy using URL as feature\n",
      "\n",
      "NB Accuracy: 0.3611111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.35555555555555557\n",
      "Linear SVM Accuracy: 0.3\n",
      "Random Forest accuracy: 0.3277777777777778\n",
      "Flair detection accuracy using Features Group(title + url) as feature\n",
      "\n",
      "NB Accuracy: 0.48333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aditya kumar\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.4666666666666667\n",
      "Linear SVM Accuracy: 0.4527777777777778\n",
      "Random Forest accuracy: 0.4638888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"Flair detection accuracy using TITLE as feature\\n\")\n",
    "train_test(reddit_data['title'])\n",
    "print(\"Flair detection accuracy using URL as feature\\n\")\n",
    "train_test(reddit_data['url'])\n",
    "print(\"Flair detection accuracy using Features Group(title + url) as feature\\n\")\n",
    "train_test(reddit_data['feature_Grp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped Features using Linear SVM Model provides most accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM Accuracy: 0.5333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model using Pickle library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X = reddit_data['title']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state = 42)\n",
    "sgd = Pipeline([('vect', CountVectorizer(max_features = 500)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge',penalty='l2',alpha=1e-3, random_state=47, max_iter=500, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "pickle.dump(sgd.fit(X_train, y_train), open(\"model_linear_svm.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
